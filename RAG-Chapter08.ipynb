{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPoJF3AF2CcKQH/Y0qX1EXG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install langchain langchain-openai langgraph pydantic"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"CDVs4bfIMBJm","executionInfo":{"status":"ok","timestamp":1760662306127,"user_tz":-540,"elapsed":20750,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"eeb4dc5c-1903-413b-a1f2-0b50cf76c147"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n","Collecting langgraph\n","  Downloading langgraph-0.6.10-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.10)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.78)\n","Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n","Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.33)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n","Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n","Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n","Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n","  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n","Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n","  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n","Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n","  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (4.15.0)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n","Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n","  Downloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n","Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (0.11.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.10.5)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n","Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph-0.6.10-py3-none-any.whl (155 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_checkpoint-2.1.2-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n","Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ormsgpack-1.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph\n","Successfully installed langchain-openai-0.3.35 langgraph-0.6.10 langgraph-checkpoint-2.1.2 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.9 ormsgpack-1.11.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7mP8UHlCLNlm"},"outputs":[],"source":["import os\n","from google.colab import userdata\n","\n","os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n","os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n","os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n","os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n","os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""]},{"cell_type":"code","source":["ROLES = {\n","    \"1\": {\n","        \"name\": \"일반 지식 전문가\",\n","        \"description\": \"폭넓은 분야의 일반적인 질문에 답변\",\n","        \"details\": \"폭넓은 분야의 일반적인 질문에 대해 정확하고 이해하기 쉬운 답변을 제공하세요.\"\n","    },\n","    \"2\": {\n","        \"name\": \"생성형 AI 제품 전문가\",\n","        \"description\": \"생성형 AI와 관련된 제품, 기술에 관한 전문적인 질문에 답변\",\n","        \"details\": \"생성형 AI와 관련 제품, 기술에 관현 전문적인 질문에 대해 최신 정보와 깊은 통찰력을 제공하세요.\"\n","    },\n","    \"3\": {\n","        \"name\": \"카운슬러\",\n","        \"description\": \"개인적인 고민이나 심리적인 문제에 대해 지원 제공\",\n","        \"details\": \"개인적인 고민이나 심리적인 문제에 대해 공감적이고 지원적인 답변을 제공하고, 가능하다면 적절한 조언도 해주세요.\"\n","    }\n","}"],"metadata":{"id":"kpH_qggYOuWE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 스테이트 정의\n","import operator\n","from typing import Annotated\n","from pydantic import BaseModel, Field\n","\n","class State(BaseModel):\n","    query: str = Field(..., description=\"사용자의 질문\")\n","    current_role: str = Field(default=\"\", description=\"선정된 답변 역할\")\n","    messages: Annotated[list[str], operator.add] = Field(default=[], description=\"답변 기록\")\n","    current_judge: bool = Field(default=False, description=\"품질 체크 결과\")\n","    judgement_reason: str = Field(default=\"\", description=\"품질 체크 판정 이유\")\n","\n","# Chat Model 초기화\n","from langchain_openai import ChatOpenAI\n","from langchain_core.runnables import ConfigurableField\n","\n","llm = ChatOpenAI(model=\"gpt-5-nano\", temperature=0.0)\n","# 나중에 max_tokens 값을 변경할 수 있도록 변경 가능한 필드 선언\n","# llm = llm.configurable_fields(max_tokens=ConfigurableField(id=\"max_tokens\"))"],"metadata":{"id":"uH8uFo1tT8zP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Selection 노드 구현\n","from typing import Any\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","\n","def selection_node(state: State) -> dict[str, Any]:\n","  query = state.query\n","  role_options = \"\\n\".join([f\"{k}. {v['name']}: {v['description']}\" for k, v in ROLES.items()])\n","\n","  prompt = ChatPromptTemplate.from_template(\"\"\"\n","  질문을 분석하고, 가장 적절한 답변 담당 역할을 선택하세요.\n","  선택지:\n","  {role_options}\n","\n","  답변은 선택지의 번호(1, 2, 또는 3)만 반환하세요.\n","\n","  질문: {query}\n","  \"\"\".strip())\n","\n","  # 선택지의 번호만 반환하기를 기대하므로 max_tokens 값을 1로 변경\n","  chain = prompt | llm.with_config(configurable={\"max_tokens\": 1}) | StrOutputParser()\n","\n","  role_number = chain.invoke({\"role_options\": role_options, \"query\": query})\n","\n","  selected_role = ROLES[role_number.strip()][\"name\"]\n","\n","  return {\"current_role\": selected_role}"],"metadata":{"id":"aUehTPe3ggGv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Answering 노드 구현\n","def answering_node(state: State) -> dict[str, Any]:\n","  query = state.query\n","  role = state.current_role\n","  role_details = \"\\n\".join([f\"- {v['name']}: {v['details']}\" for v in ROLES.values()])\n","\n","  prompt = ChatPromptTemplate.from_template(\"\"\"\n","  당신은 {role}로서 답변하세요. 다음 질문에 대해 당신의 역할에 기반한 적절한 답변을 제공하세요.\n","\n","  역할 상세:\n","  {role_details}\n","\n","  질문: {query}\n","\n","  답변:\n","  \"\"\".strip())\n","\n","  chain = prompt | llm | StrOutputParser()\n","  answer = chain.invoke({\"role\": role, \"role_details\": role_details, \"query\": query})\n","  return {\"messages\": [answer]}"],"metadata":{"id":"ececJ1j-iQmq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check 노드 구현\n","class Judgement(BaseModel):\n","  judge: bool = Field(default=False, description=\"판정 결과\")\n","  reason: str = Field(default=\"\", description=\"판정 이유\")\n","\n","def check_node(state: State) -> dict[str, Any]:\n","  query  = state.query\n","  answer = state.messages[-1]\n","  prompt = ChatPromptTemplate.from_template(\n","\"\"\"다음 답변의 품질을 체크하고, 문제가 있으면 'False', 문제가 없으면 'True'로 답변하세요.\n","또한, 그 판정 이유도 설명하세요.\n","\n","사용자의 질문: {query}\n","답변: {answer}\n","\"\"\".strip()\n","  )\n","\n","  chain = prompt | llm.with_structured_output(Judgement)\n","\n","  result: Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n","\n","  return {\n","      \"current_judge\": result.judge,\n","      \"judgement_reason\": result.reason\n","  }"],"metadata":{"id":"kUah9b9uqf2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 그래프 생성\n","from langgraph.graph import StateGraph\n","\n","workflow = StateGraph(State)\n","\n","# 노드 추가\n","workflow.add_node(\"selection\", selection_node)\n","workflow.add_node(\"answering\", answering_node)\n","workflow.add_node(\"check\", check_node)\n","\n","# 에지 정의\n","# selection 노드에서 처리 시작\n","workflow.set_entry_point(\"selection\")\n","# selection 노드에서 answering 노드로\n","workflow.add_edge(\"selection\", \"answering\")\n","# answering 노드에서 check 노드로\n","workflow.add_edge(\"answering\", \"check\")\n","\n","# 조건부 에지 정의\n","from langgraph.graph import END\n","workflow.add_conditional_edges(\n","    \"check\",\n","    lambda state: state.current_judge,\n","    {True: END, False: \"selection\"}\n",")\n","\n","compiled = workflow.compile()\n","\n","initial_state = State(query=\"생성형 AI에 관해 알려주세요.\")\n","result = compiled.invoke(initial_state)"],"metadata":{"id":"bZLIfjyHwIvH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","print(json.dumps(result, ensure_ascii=False, indent=2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13Rt4URE3VUl","executionInfo":{"status":"ok","timestamp":1760666140913,"user_tz":-540,"elapsed":30,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"3d5fa99c-bad5-4235-e9cb-4f1254fd926b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"query\": \"생성형 AI에 관해 알려주세요.\",\n","  \"current_role\": \"생성형 AI 제품 전문가\",\n","  \"messages\": [\n","    \"다음은 생성형 AI에 대해 일반 지식, 제품 관점, 그리고 필요한 경우 개인 상담 관점까지 포괄적으로 정리한 답변입니다.\\n\\n1) 생성형 AI란 무엇인가\\n- 정의: 데이터를 바탕으로 새로운 콘텐츠를 생성하는 AI 기술의 총칭으로, 텍스트, 이미지, 코드, 음악, 영상 등 다양한 형식의 창작물이 가능하도록 학습된 모델을 말합니다.\\n- 핵심 기술: 대형 언어 모델(Large Language Models, LLM), 확산 모델(Diffusion Models) 등으로 구성되며, 멀티모달 모델은 텍스트-이미지-음성 등을 함께 다룹니다.\\n- 학습 방식의 구성 요소:\\n  - 사전 학습(pretraining): 방대한 데이터로 패턴과 구조를 학습.\\n  - 미세조정(finetuning)/지시적 학습(instruction tuning): 특정 작업에 맞춘 성능 향상.\\n  - 사람의 피드백을 활용한 학습(RLHF: Reinforcement Learning from Human Feedback): 모델의 출력 품질을 사람의 선호에 맞춰 정렬.\\n  - 검색(RAG: Retrieval-Augmented Generation): 외부 지식 소스와 연결해 사실성 및 최신성 보강.\\n- 적용 범위: 텍스트 생성, 코드 작성, 디자인 및 이미지 생성, 데이터 보강, 시뮬레이션, 교육 도구 등 광범위.\\n\\n2) 작동 원리의 간단한 그림\\n- 입력 프롬프트(prompt) 또는 명령으로 시작.\\n- 모델은 학습된 패턴과 맥락을 바탕으로 결과물을 생성.\\n- 필요 시 외부 도구(계산기, 데이터베이스, 검색 엔진, 코드 런타임 등)와 연결해 기능 확장.\\n- 출력물은 사람의 검토를 통해 수정-승인될 수 있으며, 피드백 루프를 통해 성능이 개선됩니다.\\n\\n3) 현재 트렌드와 대표 사례\\n- 멀티모달isation: 텍스트뿐 아니라 이미지, 비디오, 음성까지 한 시스템에서 다루는 모델이 증가.\\n- 에이전트형 AI: 도구 사용 및 작업 계획/실행이 가능한 ‘에이전트’ 형태의 애플리케이션이 확산.\\n- 도구 사용 및 플러그인 생태계: 데이터베이스, 코딩 도구, 클라우드 서비스와의 통합이 표준화되고 있음.\\n- 대표적 예시(일반적 범주):\\n  - LLM 기반의 대화형 모델(예: 텍스트 생성 및 대화 엔진)\\n  - 이미지/비디오 생성 모델(다양한 스타일과 해상도 지원)\\n  - 코드 생성 및 자동화 도구(코드 작성 보조, 디버깅, 데이터 처리 스크립트 생성)\\n- 주의점: 기능이 강력하더라도 사실성, 저작권, 데이터 프라이버시 등의 이슈가 함께 증가하므로 운영 시 주의가 필요.\\n\\n4) 생성형 AI를 제품으로 만들 때의 주요 고려사항(제품 관점)\\n- 문제 정의와 KPI\\n  - 해결하고자 하는 실제 업무 문제를 명확히 정의.\\n  - 핵심 성과지표(KPI): 정확도, 허위정보 감소율, 평균 처리 시간, 비용/리소스 소비, 사용자 만족도, 재사용률 등.\\n- 사용자 시나리오와 UX\\n  - 프롬프트 설계 템플릿, 샘플 입력/출력 예시, 실패 시 대체 경로를 값비싼 도메인에 맞춰 구성.\\n  - 사용성과 신뢰성: 모델의 한계를 명확히 표기하고, 인간 검토가 필요한 경우를 안내.\\n- 데이터 거버넌스와 컴플라이언스\\n  - 데이터 출처 관리, 저작권/데이터 소유권 이슈, 데이터 프라이버시 보장.\\n  - 모델 카드를 통해 위험도, 한계, 데이터 사용 정책을 공개적으로 공유.\\n- 안전성 및 책임성\\n  - 입력/출력 필터링, 안전 가드레일, 악용 방지.\\n  - 편향 관리, 사실성 검증, 출처 표기 및 인용 정책.\\n- 인프라/운영 측면\\n  - 응답 속도(latency), 처리량, 비용 관리, 캐싱 전략.\\n  - 모니터링 대시보드: 출력 품질, 오류 유형, 패턴(허위정보, 편향) 추적.\\n- 도입 로드맵과 ROI\\n  - 파일럿 -> 파일럿 피드백 반영 -> 점진적 확장 순으로 설계.\\n  - 총소유비용(TCO) 대비 생산성 증가, 품질 개선, 새로운 수익 기회 등의 ROI를 예측.\\n- 제품 구조의 설계 원칙\\n  - LLM+도구 연동 아키텍처: 핵심 LLM과 외부 도구를 모듈로 분리.\\n  - 프롬프트 라이브러리 관리: 재사용 가능한 프롬프트 저장소와 버전 관리.\\n  - 거버넌스와 보안: 접근 제어, 데이터 암호화, 감사 로그.\\n\\n5) 도전 과제와 위험 관리\\n- 신뢰 문제: 허위 진술(hallucinations)과 불완전 정보.\\n- 편향과 공정성: 데이터 편향으로 인한 차별적 결과 방지.\\n- 저작권 및 데이터 소유권: 학습 데이터의 사용 의도와 결과물의 권리 문제.\\n- 개인정보 및 민감정보: 입력 데이터의 민감정보 처리와 보안.\\n- 안전성: 검열 필요성, 악용 가능성(스팸, 자동화된 악의적 콘텐츠 생성 등).\\n- 규제 및 윤리: 각국의 AI 규제/가이드라인에 대응하는 준수 체계 필요.\\n\\n6) 실전 도입을 위한 실행 가이드(간단한 체크리스트)\\n- 문제 정의 및 목표 수립\\n- 데이터 거버넌스 구축(데이터 소스, 사용 권한, 보안)\\n- KPI 선정 및 벤치마크 목표 설정\\n- 파일럿 설계: 한정된 도메인/사용자와 시작\\n- 안전성 및 거버넌스 점검: 필터링, 로그, 오용 방지\\n- 비용-효율성 분석: 토큰/요금 모델, 인프라 비용\\n- 피드백 루프 구축: 사용자 피드백 수집, 모델 재학습 주기 설정\\n- 규제·법적 검토: 저작권, 개인정보, 데이터 사용 정책 점검\\n\\n7) 프롬프트 엔지니어링과 실무 팁\\n- 명확하고 구체적인 지시문 제공: 원하는 형식, 톤, 길이, 예시 포함.\\n- 맥락 설계: 필요한 정보만 담고, 과도한 정보로 혼란 방지.\\n- 예시 프롬프트 템플릿: 입력 예시, 기대 출력 형식, 제약조건 제시.\\n- 다단계 처리: 먼저 요약, 그다음 상세 생성 등 단계적 질문 구성.\\n- 도구 연동: 계산기, 데이터 조회, 코드 실행 등 외부 도구와의 연결로 신뢰성 향상.\\n- 안전성 검사 루프: 출력물이 민감 정보나 저작권 이슈를 내포하는지 자동 검토.\\n\\n8) 개인적 상황에 대한 부가 조언(심리적/정서적 측면)\\n- 생성형 AI 도입은 큰 변화이므로 불안감이나 과도한 기대가 생길 수 있습니다.\\n- 필요하다면 작은 파일럿부터 시작하고, 명확한 성공 기준을 먼저 설정하세요.\\n- 기술과 도구에 대한 학습은 점진적으로 진행하고, 인간의 판단과 협업하는 방식으로 사용해 보세요.\\n- 질문이 개인적 고민이나 우려와 연결된다면, 구체적인 상황을 공유해 주시면 공감하는 대화와 함께 현실적인 조언도 드리겠습니다.\\n\\n원하시면 특정 산업이나 용도(예: 마케팅 콘텐츠 자동화, 코드 보조 도구, 데이터 요약 서비스 등)로 맞춰 더 구체적인 로드맷, 프롬프트 예시, 벤치마크 지표를 제시해 드리겠습니다. 또한 도입하려는 환경이나 제약 조건(예: 예산, 데이터 위치, 보안 수준)에 대해 알려주시면 더 맞춤형 조언을 드릴 수 있습니다.\"\n","  ],\n","  \"current_judge\": true,\n","  \"judgement_reason\": \"해당 답변은 생성형 AI의 정의와 핵심 기술, 학습 방식(RLHF, RAG 포함), 작동 원리, 현재 트렌드, 대표 사례, 제품 개발 시 고려사항, 도전 과제 및 위험 관리, 실전 도입 가이드, 프롬프트 엔지니어링 팁, 개인적 조언까지 포괄적으로 체계적으로 정리되어 있습니다. 내용이 정확하고 실무 적용에 유용하며, 안전성/데이터 거버넌스와 규제 이슈에 대한 주의도 함께 다루고 있어 품질이 높습니다. 다만 구체적 산업 사례나 수치/출처를 더하면 깊이가 더해질 수 있습니다.\"\n","}\n"]}]},{"cell_type":"code","source":["# 그래프 구조 시각화\n","# apt-get install graphviz libgraphviz-dev pkg-config\n","# pip install pygraphviz\n","\n","# from IPython.display import Image\n","# Image(compiled.get_graph().draw_png())"],"metadata":{"id":"0E4x2sIQ4vVF"},"execution_count":null,"outputs":[]}]}