{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO8D7RuXHBrzDk1thi7mKWS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"2G7iq1asfnDH"},"outputs":[],"source":["# LangChain 개요\n","# LangChain은 LLM 애플리케이션 개발 프레임워크이다.\n","\n","# LangChain의 다양한 컴포넌트를 제공하는 패키지 그룹\n","# 1. langchain-core\n","# LangChain의 기반이 되는 추상화와 LangChain Expression Language(LCEL)를 제공하는 패키지\n","\n","# 2. partners(langchain-openai 등)와 langchain-community\n","# LangChain에는 OpenAI나 Anthropic 등의 언어 모델을 비롯해 다양한 서비스나 OSS와의 통합이 구현되어 있다.\n","# langchain-core가 제공하는 추상 기본 클래스에 대한 구현 클래스를 설치해서 사용한다.\n","# partners 패키지로 독립되지 않은 각종 통합에 대해서는 langchain-community라는 패키지에서 함께 제공된다.\n","\n","# langchain·langchain-text-splitters·langchain-experimental\n","# langchain 패키지는 LLM 애플리케이션의 특정 유스케이스에 특화된 기능을 제공한다.\n","# 또한  LangChain의 기능 중 텍스트를 '청크'라고 불리는 단위로 분할하는 Text splitter라는 기능은\n","# langchain-text-splitters라는 별도의 패키지로 제공한다.\n","# 연구·실험 목적의 코드나 알려진 취약점(CVE)을 포함하는 코드는 langchain-experimental이라는 패키지로 분리됨."]},{"cell_type":"code","source":["# LangChain 설치\n","!pip install langchain-core==0.3.0 langchain-openai==0.2.0 pydantic==2.9.2"],"metadata":{"id":"rBQR8Jjfh02D","colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1757203687293,"user_tz":-540,"elapsed":18407,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"3eca3a15-1dc0-4fa2-e75d-43c12f99b805"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain-core==0.3.0\n","  Downloading langchain_core-0.3.0-py3-none-any.whl.metadata (6.2 kB)\n","Collecting langchain-openai==0.2.0\n","  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n","Collecting pydantic==2.9.2\n","  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.0) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.0) (1.33)\n","Collecting langsmith<0.2.0,>=0.1.117 (from langchain-core==0.3.0)\n","  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n","Collecting packaging<25,>=23.2 (from langchain-core==0.3.0)\n","  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.0) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core==0.3.0) (4.15.0)\n","Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.2.0) (1.104.2)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai==0.2.0) (0.11.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic==2.9.2) (0.7.0)\n","Collecting pydantic-core==2.23.4 (from pydantic==2.9.2)\n","  Downloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.0) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (0.28.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (3.11.3)\n","Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (2.32.4)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (1.0.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.0) (2024.11.6)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (0.16.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (3.4.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core==0.3.0) (2.5.0)\n","Downloading langchain_core-0.3.0-py3-none-any.whl (405 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_core-2.23.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pydantic-core, packaging, pydantic, langsmith, langchain-core, langchain-openai\n","  Attempting uninstall: pydantic-core\n","    Found existing installation: pydantic_core 2.33.2\n","    Uninstalling pydantic_core-2.33.2:\n","      Successfully uninstalled pydantic_core-2.33.2\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 25.0\n","    Uninstalling packaging-25.0:\n","      Successfully uninstalled packaging-25.0\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 2.11.7\n","    Uninstalling pydantic-2.11.7:\n","      Successfully uninstalled pydantic-2.11.7\n","  Attempting uninstall: langsmith\n","    Found existing installation: langsmith 0.4.23\n","    Uninstalling langsmith-0.4.23:\n","      Successfully uninstalled langsmith-0.4.23\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.75\n","    Uninstalling langchain-core-0.3.75:\n","      Successfully uninstalled langchain-core-0.3.75\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","mcp 1.13.1 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n","langchain-text-splitters 0.3.11 requires langchain-core<2.0.0,>=0.3.75, but you have langchain-core 0.3.0 which is incompatible.\n","langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 0.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed langchain-core-0.3.0 langchain-openai-0.2.0 langsmith-0.1.147 packaging-24.2 pydantic-2.9.2 pydantic-core-2.23.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["packaging"]},"id":"77bcbfec86294199994bc7e210594613"}},"metadata":{}}]},{"cell_type":"code","source":["import os\n","from google.colab import userdata\n","\n","# LangSmith 설정\n","os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n","os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n","os.environ['LANGCHAIN_API_KEY'] = userdata.get('LANGCHAIN_API_KEY')\n","os.environ['LANGCHAIN_PROJECT'] = \"default\"\n","\n","os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"],"metadata":{"id":"Tp_JVnIGk-0h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LangChain의 주요 컴포넌트 개요\n","# 1. LLM/Chat model: 다양한 언어 모델과의 통합\n","# 2. Prompt template: 프롬프트의 템플릿\n","# 3. Example selector: Few-shot 프롬프팅의 예시를 동적으로 선택\n","# 4. Output parser: 언어 모델의 출력을 지정한 형식으로 변환\n","# 5. Chain: 각종 컴포넌트를 사용한 처리의 연쇄\n","# 6. Document loader: 데이터 소스에서 문서를 읽어 들임\n","# 7. Document transformer: 문서에 어떤 변환을 가함\n","# 8. Embedding model: 문서를 벡터화함\n","# 9. Vector store: 벡터화한 문서의 저장소\n","# 10. Retriever: 입력 텍스트와 관련된 문서를 검색\n","# 11. Tool: Function calling 등에서 모델이 사용하는 함수를 추상화\n","# 12. Toolkit: 함께 사용하는 것을 가정한 Tool의 컬렉션\n","# 13. Chat history: 대화 이력의 저장소로서의 각종 데이터베이스와의 통합"],"metadata":{"id":"EZNw36gM4zpd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LLM/Chat model - Completions API\n","from langchain_openai import ChatOpenAI\n","\n","model = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n","output = model.invoke(\"안녕하세요.\")\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":406},"id":"yHQqLdPeSDyS","executionInfo":{"status":"error","timestamp":1757203618178,"user_tz":-540,"elapsed":36,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"d5337c16-ee5f-4a86-e150-3d47ccf9e6b2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'langchain_openai'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3458360815.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# LLM/Chat model - Completions API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo-instruct\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"안녕하세요.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# LLM/Chat model - Chat Completions API\n","from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n","from langchain_openai import ChatOpenAI\n","\n","model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n","\n","messages = [\n","    # \"role\": \"system\"\n","    SystemMessage(\"You are a helpful assistant.\"),\n","    # \"role\": \"user\"\n","    HumanMessage(\"안녕하세요! 저는 Edward라고 합니다.\"),\n","    # \"role\": \"assistent\"\n","    AIMessage(content=\"안녕하세요, Edward님! 어떤 도움이 필요하신가요?\"),\n","    # \"role\": \"user\"\n","    HumanMessage(content=\"제 이름을 아시나요?\")\n","]\n","\n","ai_message = model.invoke(messages)\n","\n","print(ai_message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KOUw-2fVppr6","executionInfo":{"status":"ok","timestamp":1756777589238,"user_tz":-540,"elapsed":1098,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"e1bd1193-6ea7-40e1-bf7e-8ba344407d52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["네, Edward님이라고 말씀하셨습니다. 어떻게 도와드릴까요?\n","[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}), HumanMessage(content='안녕하세요! 저는 Edward라고 합니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요, Edward님! 어떤 도움이 필요하신가요?', additional_kwargs={}, response_metadata={}), HumanMessage(content='제 이름을 아시나요?', additional_kwargs={}, response_metadata={})]\n"]}]},{"cell_type":"code","source":["# 스트리밍 응답\n","from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n","from langchain_openai import ChatOpenAI\n","\n","model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n","\n","messages = [\n","    SystemMessage(\"You are a helpful assistant.\"),\n","    HumanMessage(\"안녕하세요!\")\n","]\n","\n","for chunk in model.stream(messages):\n","  print(chunk.content, end=\"\", flush=True)\n","\n","# 참고로, LangChain에서는 Callback 기능을 사용하여 스트리밍 구현 가능\n","# 처리 시작(on_llm_start)\n","# 새로운 토큰 생성(on_llm_new_token)\n","# LLM 처리 종료(on_llm_end)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hNrS4c4G7oxu","executionInfo":{"status":"ok","timestamp":1756456045527,"user_tz":-540,"elapsed":577,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"4f29e261-e393-4e27-e914-3cf98795d0c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["안녕하세요! 어떻게 도와드릴까요?"]}]},{"cell_type":"code","source":["# PromptTemplate\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"사용자가 입력한 요리의 레시피를 생각해 주세요.\"),\n","        (\"human\",  \"{dish}\")\n","    ]\n",")\n","\n","prompt_value = prompt.invoke({\"dish\": \"카레\"})\n","print(prompt_value)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WsHsLENxE6x3","executionInfo":{"status":"ok","timestamp":1756715451054,"user_tz":-540,"elapsed":45,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"5ac71276-b6f6-49ef-b82d-ad7b0718908b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["messages=[SystemMessage(content='사용자가 입력한 요리의 레시피를 생각해 주세요.', additional_kwargs={}, response_metadata={}), HumanMessage(content='카레', additional_kwargs={}, response_metadata={})]\n"]}]},{"cell_type":"code","source":["# MessagesPlaceholder\n","from langchain_core.messages import AIMessage, HumanMessage\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"You are a helpful assistant.\"),\n","        MessagesPlaceholder(\"chat_history\", optional=True),\n","        (\"human\", \"{input}\")\n","    ]\n",")\n","\n","prompt_value = prompt.invoke(\n","    {\n","        \"chat_history\": [\n","            HumanMessage(content=\"안녕하세요! 저는 Edward라고 합니다.\"),\n","            AIMessage(\"안녕하세요, Edward님! 어떻게 도와드릴까요?\")\n","        ],\n","        \"input\": \"제 이름을 아시나요?\",\n","    }\n",")\n","print(prompt_value)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwnOsMzQZ3VE","executionInfo":{"status":"ok","timestamp":1756715790825,"user_tz":-540,"elapsed":14,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"91e4a839-35c3-4a94-a557-d651cf0d49ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["messages=[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}), HumanMessage(content='안녕하세요! 저는 Edward라고 합니다.', additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요, Edward님! 어떻게 도와드릴까요?', additional_kwargs={}, response_metadata={}), HumanMessage(content='제 이름을 아시나요?', additional_kwargs={}, response_metadata={})]\n"]}]},{"cell_type":"code","source":["# Output parser\n","# LLM에 특정 형식으로 출력하도록 하고, 그 출력을 프로그램적으로 다루고 싶은 경우가 있다.\n","# 이때 사용할 수 있는 것이 'Output parser'이다.\n","# Json 등의 출력 형식을 지정하는 프롬프트 작성과 응답 텍스트를 Python 객체로 변환하는 기능을 제공한다.\n","\n","# Pydantic 모델로 정의한다.\n","from pydantic import BaseModel, Field\n","\n","class Recipe(BaseModel):\n","  ingredients: list[str] = Field(description=\"ingredients of the dish\")\n","  step:list[str] = Field(description=\"steps to make the dish\")\n","\n","# Recipe 클래스를 제공해 PydanticOutputParser를 생성한다.\n","from langchain_core.output_parsers import PydanticOutputParser\n","\n","output_parser = PydanticOutputParser(pydantic_object=Recipe)\n","\n","format_instructions = output_parser.get_format_instructions()\n","\n","print(format_instructions)\n","\n","# 이어서 format_instructions를 사용한 ChatPromptTemplate을 생성한다.\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"사용자가 입력한 요리의 레시피를 생각해 주세요.\\n\\n\"\n","            \"{format_instructions}\"\n","        ),\n","        (\"human\", \"{dish}\")\n","    ]\n",")\n","\n","prompt_with_format_instructions = prompt.partial(\n","    format_instructions=format_instructions\n",")\n","\n","prompt_value = prompt_with_format_instructions.invoke({\"dish\": \"카레\"})\n","\n","print(\"=== role: system ===\")\n","print(prompt_value.messages[0].content)\n","print(\"=== role: user ===\")\n","print(prompt_value.messages[1].content)\n","\n","print(prompt_value)\n","\n","# 위 텍스트를 LLM의 입력으로 실행\n","from langchain_openai import ChatOpenAI\n","\n","model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n","ai_message = model.invoke(prompt_value)\n","\n","print(ai_message.content)\n","\n","# Pydantic 모델의 인스턴스로 변환\n","recipe = output_parser.invoke(ai_message)\n","\n","print(type(recipe))\n","print(recipe)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hyIjQqrYQ9CC","executionInfo":{"status":"ok","timestamp":1756777701117,"user_tz":-540,"elapsed":7104,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"0d6583f3-7700-47bd-abe7-e2432edf0d76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The output should be formatted as a JSON instance that conforms to the JSON schema below.\n","\n","As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n","the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n","\n","Here is the output schema:\n","```\n","{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"step\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Step\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"step\"]}\n","```\n","=== role: system ===\n","사용자가 입력한 요리의 레시피를 생각해 주세요.\n","\n","The output should be formatted as a JSON instance that conforms to the JSON schema below.\n","\n","As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n","the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n","\n","Here is the output schema:\n","```\n","{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"step\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Step\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"step\"]}\n","```\n","=== role: user ===\n","카레\n","messages=[SystemMessage(content='사용자가 입력한 요리의 레시피를 생각해 주세요.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"ingredients\": {\"description\": \"ingredients of the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Ingredients\", \"type\": \"array\"}, \"step\": {\"description\": \"steps to make the dish\", \"items\": {\"type\": \"string\"}, \"title\": \"Step\", \"type\": \"array\"}}, \"required\": [\"ingredients\", \"step\"]}\\n```', additional_kwargs={}, response_metadata={}), HumanMessage(content='카레', additional_kwargs={}, response_metadata={})]\n","{\n","  \"ingredients\": [\n","    \"닭고기 500g\",\n","    \"양파 1개\",\n","    \"감자 2개\",\n","    \"당근 1개\",\n","    \"카레 가루 3큰술\",\n","    \"식용유 2큰술\",\n","    \"소금 약간\",\n","    \"후추 약간\",\n","    \"물 4컵\"\n","  ],\n","  \"step\": [\n","    \"양파는 잘게 다지고, 감자와 당근은 큐브 모양으로 썬다.\",\n","    \"냄비에 식용유를 두르고 다진 양파를 넣어 볶아준다.\",\n","    \"양파가 투명해지면 닭고기를 넣고 겉면이 익을 때까지 볶는다.\",\n","    \"닭고기가 익으면 감자와 당근을 넣고 함께 볶는다.\",\n","    \"카레 가루를 넣고 잘 섞은 후 물을 부어준다.\",\n","    \"중불에서 끓기 시작하면 소금과 후추로 간을 맞춘다.\",\n","    \"약한 불로 줄이고 20-30분 정도 끓여서 재료가 부드러워질 때까지 조리한다.\",\n","    \"완성된 카레를 밥과 함께 서빙한다.\"\n","  ]\n","}\n","<class '__main__.Recipe'>\n","ingredients=['닭고기 500g', '양파 1개', '감자 2개', '당근 1개', '카레 가루 3큰술', '식용유 2큰술', '소금 약간', '후추 약간', '물 4컵'] step=['양파는 잘게 다지고, 감자와 당근은 큐브 모양으로 썬다.', '냄비에 식용유를 두르고 다진 양파를 넣어 볶아준다.', '양파가 투명해지면 닭고기를 넣고 겉면이 익을 때까지 볶는다.', '닭고기가 익으면 감자와 당근을 넣고 함께 볶는다.', '카레 가루를 넣고 잘 섞은 후 물을 부어준다.', '중불에서 끓기 시작하면 소금과 후추로 간을 맞춘다.', '약한 불로 줄이고 20-30분 정도 끓여서 재료가 부드러워질 때까지 조리한다.', '완성된 카레를 밥과 함께 서빙한다.']\n"]}]},{"cell_type":"code","source":["# StrOutputParser\n","# LLM의 출력을 텍스트로 변환하는 데 사용한다.\n","\n","from langchain_core.messages import AIMessage\n","from langchain_core.output_parsers import StrOutputParser\n","\n","output_parser = StrOutputParser()\n","\n","ai_message = AIMessage(content=\"안녕하세요. 저는 AI 어시스턴트입니다.\")\n","ai_message = output_parser.invoke(ai_message)\n","\n","print(type(ai_message))\n","print(ai_message)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWEQIqbsA_L_","executionInfo":{"status":"ok","timestamp":1756776297038,"user_tz":-540,"elapsed":18,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"83b3f1f4-26ac-4b71-8e00-2ebf67765cc5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'str'>\n","안녕하세요. 저는 AI 어시스턴트입니다.\n"]}]},{"cell_type":"code","source":["# Chain-LangChain Expression Language(LCEL)\n","# LCEL에서는 프롬프트나 LLM을 '|'로 연결하여 작성하고 처리의 연쇄(Chain)를 구현한다.\n","\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", \"사용자가 입력한 요리의 레시피를 생각해 주세요.\"),\n","        (\"human\", \"{dish}\")\n","    ]\n",")\n","\n","model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n","\n","chain = prompt | model\n","\n","ai_message = chain.invoke({\"dish\": \"카레\"})\n","print(ai_message.content)"],"metadata":{"id":"XSAaAVIwHuh8","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1756782606584,"user_tz":-540,"elapsed":10037,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"6343ede6-8f6c-46f1-94ab-b8508a6a5a20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["카레는 다양한 재료와 향신료를 사용하여 만드는 맛있는 요리입니다. 아래는 기본적인 카레 레시피입니다.\n","\n","### 재료\n","- 고기 (닭고기, 소고기, 돼지고기 등) 300g\n","- 양파 1개\n","- 감자 1개\n","- 당근 1개\n","- 카레 가루 2-3 큰술\n","- 코코넛 밀크 또는 물 2컵\n","- 식용유 2 큰술\n","- 소금, 후추 약간\n","- 마늘 2쪽 (다진 것)\n","- 생강 1 작은 조각 (다진 것)\n","- 선택 재료: 피망, 버섯, 완두콩 등\n","\n","### 조리 방법\n","1. **재료 손질**: 고기는 한 입 크기로 자르고, 양파는 다지고, 감자와 당근은 깍둑썰기 합니다.\n","\n","2. **양파 볶기**: 큰 냄비에 식용유를 두르고 중불에서 다진 양파를 넣고 투명해질 때까지 볶습니다.\n","\n","3. **마늘과 생강 추가**: 다진 마늘과 생강을 넣고 향이 올라올 때까지 볶습니다.\n","\n","4. **고기 추가**: 손질한 고기를 넣고 겉면이 익을 때까지 볶습니다.\n","\n","5. **채소 추가**: 감자와 당근을 넣고 함께 볶습니다.\n","\n","6. **카레 가루 추가**: 카레 가루를 넣고 잘 섞어줍니다. 이때 향신료의 향이 나기 시작합니다.\n","\n","7. **액체 추가**: 코코넛 밀크 또는 물을 부어주고, 소금과 후추로 간을 맞춥니다.\n","\n","8. **끓이기**: 끓어오르면 불을 줄이고 뚜껑을 덮고 20-30분 정도 끓입니다. 중간에 저어주면서 재료가 골고루 익도록 합니다.\n","\n","9. **마무리**: 원하는 경우 마지막에 피망, 버섯, 완두콩 등을 추가하고 5분 정도 더 끓입니다.\n","\n","10. **서빙**: 밥과 함께 따뜻하게 서빙합니다.\n","\n","맛있게 드세요! 카레는 취향에 따라 다양한 재료와 향신료를 추가하여 변형할 수 있습니다.\n"]}]},{"cell_type":"code","source":["# Chain-LangChain Expression Language(LCEL)\n","# StrOutputParser를 연결에 추가\n","from langchain_core.output_parsers import StrOutputParser\n","\n","chain = prompt | model | StrOutputParser()\n","\n","output = chain.invoke({\"dish\": \"카레\"})\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"naaCwkf-Z1O0","executionInfo":{"status":"ok","timestamp":1756782931657,"user_tz":-540,"elapsed":9059,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"c321b814-71e2-4e61-c4b3-c0206ae61e88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["카레는 다양한 재료와 향신료를 사용하여 만드는 맛있는 요리입니다. 아래는 기본적인 카레 레시피입니다.\n","\n","### 재료\n","- 고기 (닭고기, 소고기, 돼지고기 등) 300g\n","- 양파 1개\n","- 감자 1개\n","- 당근 1개\n","- 카레 가루 2-3 큰술\n","- 식용유 2 큰술\n","- 물 3컵\n","- 소금, 후추 약간\n","- 선택 재료: 피망, 버섯, 완두콩 등\n","\n","### 조리 방법\n","1. **재료 손질**: 고기는 한 입 크기로 자르고, 양파는 다지고, 감자와 당근은 깍둑썰기 합니다.\n","\n","2. **양파 볶기**: 큰 냄비에 식용유를 두르고 중불에서 다진 양파를 넣어 투명해질 때까지 볶습니다.\n","\n","3. **고기 추가**: 양파가 볶아지면 고기를 넣고 겉면이 익을 때까지 볶습니다.\n","\n","4. **채소 추가**: 감자와 당근을 넣고 함께 볶아줍니다.\n","\n","5. **물 붓기**: 재료가 잘 섞이면 물을 붓고 끓입니다. 끓기 시작하면 불을 줄이고 중약불로 15-20분 정도 끓입니다.\n","\n","6. **카레 가루 추가**: 카레 가루를 넣고 잘 섞은 후, 다시 10분 정도 끓입니다. 필요에 따라 소금과 후추로 간을 맞춥니다.\n","\n","7. **완성**: 카레가 걸쭉해지면 불을 끄고, 밥과 함께 서빙합니다.\n","\n","### 팁\n","- 카레는 시간이 지날수록 맛이 깊어지므로, 하루 정도 숙성시키면 더욱 맛있습니다.\n","- 다양한 채소나 해산물을 추가하여 나만의 카레를 만들어 보세요.\n","\n","맛있게 드세요!\n"]}]},{"cell_type":"code","source":["from langchain_core.output_parsers import PydanticOutputParser\n","from pydantic import BaseModel, Field\n","\n","class Recipe(BaseModel):\n","  ingredients: list[str] = Field(description=\"ingredients of the dish\")\n","  step: list[str] = Field(description=\"steps to make the dish\")\n","\n","output_parser = PydanticOutputParser(pydantic_object=Recipe)\n","\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"사용자가 입력한 요리의 레시피를 생각해 주세요.\\n\\n{format_instructions}\"\n","        ),\n","        (\"human\", \"{dish}\")\n","    ]\n",")\n","\n","prompt_with_format_instructions = prompt.partial(\n","    format_instructions=output_parser.get_format_instructions()\n",")\n","\n","model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n","\n","chain = prompt_with_format_instructions | model | output_parser\n","\n","recipe = chain.invoke({\"dish\": \"카레\"})\n","print(type(recipe))\n","print(recipe)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gaw__PC1OJBK","executionInfo":{"status":"ok","timestamp":1756796807347,"user_tz":-540,"elapsed":9525,"user":{"displayName":"김광혁","userId":"08430990677373827620"}},"outputId":"5d5f19a5-904d-4633-d55e-29ce9b33d4d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class '__main__.Recipe'>\n","ingredients=['닭고기 500g', '양파 1개', '당근 1개', '감자 2개', '카레 가루 3큰술', '식용유 2큰술', '소금 약간', '후추 약간', '물 4컵'] step=['닭고기를 한 입 크기로 썰고, 소금과 후추로 간을 한다.', '양파, 당근, 감자를 깍둑썰기로 준비한다.', '팬에 식용유를 두르고 양파를 볶아 투명해질 때까지 볶는다.', '닭고기를 넣고 겉면이 익을 때까지 볶는다.', '당근과 감자를 넣고 함께 볶는다.', '물 4컵을 붓고 끓인다.', '끓기 시작하면 불을 줄이고 카레 가루를 넣는다.', '잘 섞은 후 중약불에서 20분 정도 끓인다.', '소스가 걸쭉해지면 불을 끄고, 밥과 함께 서빙한다.']\n"]}]}]}